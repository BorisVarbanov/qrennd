{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from qrennd import get_model, Config, Layout\n",
    "from qrennd.layouts.plotter import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591c026",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88d608",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_syndromes(anc_meas: xr.DataArray) -> xr.DataArray:\n",
    "    syndromes = anc_meas ^ anc_meas.shift(qec_round=1, fill_value=0)\n",
    "    syndromes.name = \"syndromes\"\n",
    "    return syndromes\n",
    "\n",
    "\n",
    "def get_defects(\n",
    "    syndromes: xr.DataArray, frame: Optional[xr.DataArray] = None\n",
    ") -> xr.DataArray:\n",
    "    shifted_syn = syndromes.shift(qec_round=1, fill_value=0)\n",
    "\n",
    "    if frame is not None:\n",
    "        shifted_syn[dict(qec_round=0)] = frame\n",
    "\n",
    "    defects = syndromes ^ shifted_syn\n",
    "    defects.name = \"defects\"\n",
    "    return defects\n",
    "\n",
    "\n",
    "def get_final_defects(\n",
    "    syndromes: xr.DataArray,\n",
    "    proj_syndrome: xr.DataArray,\n",
    ") -> xr.DataArray:\n",
    "    last_syndrome = syndromes.isel(qec_round=-1)\n",
    "    proj_anc = proj_syndrome.anc_qubit\n",
    "\n",
    "    final_defects = last_syndrome.sel(anc_qubit=proj_anc) ^ proj_syndrome\n",
    "    final_defects.name = \"final_defects\"\n",
    "    return final_defects\n",
    "\n",
    "\n",
    "def preprocess_data(dataset, proj_mat):\n",
    "    syndromes = get_syndromes(dataset.anc_meas)\n",
    "    defects = get_defects(syndromes)\n",
    "\n",
    "    proj_syndrome = (dataset.data_meas @ proj_mat) % 2\n",
    "    final_defects = get_final_defects(syndromes, proj_syndrome)\n",
    "\n",
    "    init_states = dataset.init_state.sum(dim=\"data_qubit\") % 2\n",
    "    log_states = dataset.data_meas.sum(dim=\"data_qubit\") % 2\n",
    "\n",
    "    labels = log_states.astype(int) ^ init_states\n",
    "\n",
    "    #inputs = dict(defects=defects.data, final_defects=final_defects.data)\n",
    "    inputs = dict(defects=syndromes.data, final_defects=dataset.data_meas.data)\n",
    "    #inputs = dict(defects=dataset.anc_meas.data, final_defects=dataset.data_meas.data)\n",
    "    outputs = labels.data\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f64fb7",
   "metadata": {},
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ceac9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = pathlib.Path.cwd() # define the path where the notebook is placed.\n",
    "\n",
    "LAYOUT_DIR = NOTEBOOK_DIR / \"layouts\"\n",
    "if not LAYOUT_DIR.exists():\n",
    "    raise ValueError(\"Layout directory does not exist.\")\n",
    "\n",
    "CONFIG_DIR = NOTEBOOK_DIR / \"configs\"\n",
    "if not CONFIG_DIR.exists():\n",
    "    raise ValueError(\"Config directory does not exist.\")\n",
    "\n",
    "# The train/dev/test data directories are located in the local data directory\n",
    "DATA_DIR = NOTEBOOK_DIR / \"data\"\n",
    "if not DATA_DIR.exists():\n",
    "    raise ValueError(\"Train data directory does not exist.\")\n",
    "\n",
    "cur_datetime = datetime.now()\n",
    "datetime_str = cur_datetime.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "LOG_DIR = NOTEBOOK_DIR / f\"logs/{datetime_str}\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHECKPOINT_DIR = NOTEBOOK_DIR / \"tmp/checkpoint\"\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426eaf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYOUT_FILE = \"d3_layout.yaml\"\n",
    "layout = Layout.from_yaml(LAYOUT_DIR / LAYOUT_FILE)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "plot(layout, label_qubits=True, draw_patches=True, axis=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"base_config.yaml\"\n",
    "config = Config.from_yaml(CONFIG_DIR / CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_mat = layout.projection_matrix(stab_type=\"z_type\")\n",
    "\n",
    "train_dataset = xr.load_dataset(\n",
    "    DATA_DIR / \"train/d3_surf_code_seq_round_state_0_shots_1000000_rounds_40.nc\"\n",
    ")\n",
    "train_input, train_output = preprocess_data(train_dataset, proj_mat)\n",
    "\n",
    "dev_dataset = xr.load_dataset(\n",
    "    DATA_DIR / \"dev/d3_surf_code_seq_round_state_0_shots_20000_rounds_40.nc\"\n",
    ")\n",
    "dev_input, dev_output = preprocess_data(dev_dataset, proj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc26f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "    keras.metrics.AUC(num_thresholds=100, name=\"AUC\", curve=\"ROC\")\n",
    "]\n",
    "\n",
    "aux_metrics = [\n",
    "    keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fde44",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "num_rounds = train_dataset.qec_round.size\n",
    "num_anc = train_dataset.anc_qubit.size\n",
    "\n",
    "model = get_model(\n",
    "    defects_shape=(num_rounds, num_anc),\n",
    "    final_defects_shape=(9, ),\n",
    "    config=config,\n",
    "    metrics=dict(\n",
    "        main_output = main_metrics,\n",
    "        aux_output = aux_metrics\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b2c88",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69176ffb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eefe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %tensorboard --logdir={LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8588842",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=CHECKPOINT_DIR / \"weights.hdf5\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=3\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97fa28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=train_input,\n",
    "    y=train_output,\n",
    "    validation_data=[dev_input, dev_output],\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c6eee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_dataset = xr.load_dataset(\n",
    "    DATA_DIR / \"test/d3_surf_code_seq_round_state_0_shots_20000_rounds_20.nc\"\n",
    ")\n",
    "test_input, test_output = preprocess_data(test_dataset, proj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56b919",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "eval_output = model.evaluate(x=test_input, y=test_output, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b67a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_dataset = xr.load_dataset(\n",
    "    DATA_DIR / \"test/d3_surf_code_seq_round_state_0_shots_20000_rounds_20_v2.nc\"\n",
    ")\n",
    "test_input, test_output = preprocess_data(test_dataset, proj_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba9988",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output = model.evaluate(x=test_input, y=test_output, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582bc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "667c0da509f68382cb5db87ad6084e99a8aa67a23a8521bc8a03c5d7e0fe7632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
